{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":861496,"sourceType":"datasetVersion","datasetId":457093}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport math\nimport tensorflow as tf\nimport cv2\nimport imageio\nimport matplotlib.image as mpimg\nfrom skimage import io\nfrom PIL import Image\nimport glob\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers.legacy import RMSprop,SGD\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow import keras\nfrom statistics import mode\nimport keras\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, Flatten, BatchNormalization, Dense\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(path,label):\n    dataX=[]\n    dataY=[]\n    all_images_path=glob.glob(path+'/*')\n    i = 0\n    for img_path in all_images_path:        \n            image = io.imread(img_path)\n            img = cv2.resize(image, (224,224), cv2.INTER_AREA)\n            img=img/255.0\n            img_rgb = gray2RGB(img)\n            if i < 100000:\n                \n                x_data.append(img_rgb)\n                dataX.append(img_rgb)\n                y_data.append(label)\n                dataY.append(label)\n            else: \n                break\n            \n            i = i + 1\n    \n    return  np.array(dataX),np.array(dataY)\n\n\n\n\ndef prepare_dataset_2(path,label):\n    dataX=[]\n    dataY=[]\n    all_images_path=glob.glob(path+'/*')\n    i = 0\n    for img_path in all_images_path:        \n            image = io.imread(img_path)\n            img = cv2.resize(image, (224,224), cv2.INTER_AREA)\n            img=img/255.0\n            img_rgb = gray2RGB(img)\n            if i < 1000: \n                x_data.append(img_rgb)\n                dataX.append(img_rgb)\n                y_data.append(label)\n                dataY.append(label)\n            else:\n                break\n            \n            i = i + 1\n    \n    return  np.array(dataX),np.array(dataY)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gray2RGB(array2d):\n    array3d = np.tile(array2d[:,:,np.newaxis],3)\n    return array3d\n\ndef all_img_rgb_converter(arrays2d):\n\n    len, width, height = arrays2d.shape\n    arrays3d = []\n\n    for i in range(len):\n        array3d = gray2RGB(arrays2d[i,:,:])\n        arrays3d.append(array3d)\n\n    arrays3d = np.array(arrays3d)\n    return arrays3d","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\n#Plot the confusion matrix. Set Normalize = True/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy_lr_loss_plot(history):\n    fig = plt.figure(figsize=(15,10))\n    \n    plt.subplot(231)\n    plt.plot(history.history[\"accuracy\"], 'bo--', label=\"accuracy\")\n    plt.plot(history.history['val_accuracy'], 'ro--', label=\"val_accuracy\")\n    plt.title(\"Training Data Accuracy Measurements\")\n    plt.xlabel(\"Number of epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.grid()\n    plt.legend()\n    plt.tight_layout()\n    \n    plt.subplot(232)\n    plt.plot(history.history['learning_rate'], 'go--', label=\"Learning Rate\")\n    plt.title(\"Learning Rate\")\n    plt.xlabel(\"Number of epochs\")\n    plt.ylabel(\"Learning Rate\")\n    plt.grid()\n    plt.legend()\n    plt.tight_layout()\n    \n    \n    plt.subplot(233)\n    plt.plot(history.history[\"loss\"], \"bo--\", label=\"loss\")\n    plt.plot(history.history[\"val_loss\"], \"ro--\", label = \"val_loss\")\n    plt.title(\"Training Data Loss\")\n    plt.xlabel(\"Number of epochs\")\n    plt.ylabel(\"loss\")\n    plt.grid()\n    plt.legend()\n    plt.tight_layout()\n    \n    plt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = []\ny_data = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Mild_Dementia_test = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/MildDemented\"\nModerate_Dementia_test = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/ModerateDemented\"\nNon_Demented_test = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/NonDemented\"\nVery_mild_Dementia_test = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/VeryMildDemented\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Mild_Dementia_train = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/MildDemented\"\nModerate_Dementia_train = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/ModerateDemented\"\nNon_Demented_train = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/NonDemented\"\nVery_mild_Dementia_train = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/VeryMildDemented\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Mild_Dementia_test, Y_Mild_Dementia_test =  prepare_dataset(Mild_Dementia_test,0)\nX_Moderate_Dementia_test, Y_Moderate_Dementia_test =  prepare_dataset(Moderate_Dementia_test,0)\nX_Non_Demented_test, Y_Non_Demented_test = prepare_dataset_2(Non_Demented_test,1)\nX_Very_mild_Dementia_test, Y_Very_mild_Dementia_test = prepare_dataset(Very_mild_Dementia_test,0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Mild_Dementia_train, Y_Mild_Dementia_train =  prepare_dataset(Mild_Dementia_train,0)\nX_Moderate_Dementia_train, Y_Moderate_Dementia_train =  prepare_dataset(Moderate_Dementia_train,0)\nX_Non_Demented_train, Y_Non_Demented_train = prepare_dataset_2(Non_Demented_train,1)\nX_Very_mild_Dementia_train, Y_Very_mild_Dementia_train = prepare_dataset(Very_mild_Dementia_train,0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_0 = 0\nc_1 = 0\n    \nfor i in y_data:\n    if i == 0:\n        c_0 += 1 \n    elif i == 1:\n        c_1 += 1\n    else:\n        print(\"asfaa\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications import DenseNet169\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.vgg16 import VGG16","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\n\nkf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VALIDATION_ACCURACY_DenseNet121 = []\nVALIDAITON_LOSS_DenseNet121 = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model=DenseNet169(input_shape = (224, 224, 3), \n                              include_top = False, \n                              weights = 'imagenet')\n\nfor layer in pretrained_model.layers:\n        layer.trainable = False\n        \nfor layer in pretrained_model.layers[313:]:\n        layer.trainable = True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, layer in enumerate(pretrained_model.layers):\n    print(i,'\\t',layer.trainable,'\\t  :',layer.name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_var = 1\n\n\nfor train_index, val_index in kf.split(x_data,y_data):\n    \n    if fold_var >= 1: \n        x_train_data = []\n        y_train_data = []\n\n        x_val_data = []\n        y_val_data = []\n\n\n        for i in train_index:\n          x_train_data.append(x_data[i])\n          y_train_data.append(y_data[i])\n\n\n        for i in val_index:\n          x_val_data.append(x_data[i])\n          y_val_data.append(y_data[i])\n\n\n        X_train = np.array(x_train_data)\n        Y_train = np.array(y_train_data)\n\n        X_val = np.array(x_val_data)\n        Y_val = np.array(y_val_data)\n\n        ################# DenseNet121 ##################\n        pretrained_model=DenseNet121(input_shape = (224, 224, 3), \n                                  include_top = False, \n                                  weights = 'imagenet')\n\n        for layer in pretrained_model.layers:\n            layer.trainable = False\n\n        for layer in pretrained_model.layers[313:]:\n            layer.trainable = True\n\n\n        # Define custom head for classification\n        x = pretrained_model.output\n        # x = Dropout(0.5)(x)\n        x = GlobalAveragePooling2D()(x)\n        x = BatchNormalization()(x)\n        x = Dense(8192, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(4096, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(2048, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(1024, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(512, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(256, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(128, activation='relu')(x)\n        x = BatchNormalization()(x)\n        output = Dense(2, activation='softmax')(x)\n\n\n\n        final_DenseNet121 = Model(inputs=pretrained_model.input, outputs=output)\n\n\n\n        final_DenseNet121.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01),\n                        loss = 'sparse_categorical_crossentropy', \n                        metrics = ['accuracy'])\n\n\n        #.h5 = Hierarchical Data Format Ver. 5 file, verbose =1, to see execution\n        tensorboard= tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n        checkpoint= tf.keras.callbacks.ModelCheckpoint(f\"/kaggle/working/DenseNet121_model_{fold_var}.keras\",\n                                monitor=\"val_accuracy\", verbose=1,\n                                mode=\"auto\", save_best_only=True)\n\n        early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n\n\n        #monitor: quantity to be monitored.     \n        #factor: factor by which the learning rate will be reduced. \n        #patience: number of epochs with no improvement after which learning rate will be reduced.     \n        #verbose: int. 0: quiet, 1: update messages.\n        #min_delta: early stopping of epochs\n        reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n                                factor=0.5,\n                                patience=3,verbose=1,\n                                mode=\"auto\", min_delta=0.001)\n\n\n\n        history = final_DenseNet121.fit(X_train,Y_train,\n                epochs=50,\n                validation_data=(X_val,Y_val),\n                callbacks =[tensorboard, checkpoint, reduce_lr, early_stopping_cb])\n\n\n\n        # LOAD BEST MODEL to evaluate the performance of the model\n        final_DenseNet121.load_weights(f\"/kaggle/working/DenseNet121_model_{fold_var}.keras\")\n\n        results = final_DenseNet121.evaluate(X_val,Y_val)\n        results = dict(zip(final_DenseNet121.metrics_names,results))\n\n\n        VALIDATION_ACCURACY_DenseNet121.append(results['compile_metrics'])\n        VALIDAITON_LOSS_DenseNet121.append(results['loss'])\n\n\n        #  Logic of all test database\n        Y_pred = final_DenseNet121.predict(X_val)\n        Y_pred = np.argmax(Y_pred, axis=1)\n\n\n        #  Return pro format of classes\n        target_names = [\"Mild_Dementia\", \"Non_Demented\"]\n\n        # Confusion Matrix\n        plt.figure()\n        cm = confusion_matrix(Y_val, Y_pred)\n        plot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n\n        # Save confusion matrix in text\n        np.savetxt(f\"/kaggle/working/DenseNet121_cm_{fold_var}.txt\",cm,fmt='%d')\n        plt.savefig(f\"/kaggle/working/DenseNet121_cm_img_{fold_var}.png\")\n\n        # Save clasification report in text\n        text_file = open(f\"/kaggle/working/DenseNet121_report_{fold_var}.txt\", \"w\")\n        n = text_file.write(classification_report(Y_val, Y_pred, target_names=target_names))\n        text_file.close()\n\n        #Comparing losses and accuraries \n        plt.figure()\n        plt.plot(history.history['loss'], color='r')\n        plt.plot(history.history['val_loss'], color='b')\n        plt.title(\"Loss Graph\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss Values\")\n        plt.savefig(f\"/kaggle/working/DenseNet121_loss_{fold_var}.png\")\n        plt.show()\n\n        plt.figure()\n        plt.plot(history.history['accuracy'], color='r')\n        plt.plot(history.history['val_accuracy'], color='b')\n        plt.title(\"Accuracy Graph\")\n        plt.ylabel(\"Accuracy Values\")\n        plt.xlabel(\"Epoch\")\n        plt.savefig(f\"/kaggle/working/DenseNet121_accuracy_{fold_var}.png\")\n        plt.show()\n\n        plt.figure()\n        print(VALIDATION_ACCURACY_DenseNet121)\n        print(VALIDAITON_LOSS_DenseNet121)\n\n        accuracy_lr_loss_plot(history)\n\n    \n    elif fold_var < 1:\n        print(f\"fold-{fold_var} data verileri atlandı\")\n    else:\n        print(\"yanlış bişeyler var hacı\")\n        \n    fold_var += 1\n    tf.keras.backend.clear_session() \n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}